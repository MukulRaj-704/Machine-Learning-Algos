Linear Regression is a supervised learning algorithm used to model the relationship between a dependent variable (y) and one or more independent variables (X). It’s commonly used for prediction tasks like price forecasting, trend analysis, and risk modeling.


These are the assumptions consider during Linear Regression
-->Linearity between X and y
-->Homoscedasticity (equal variance of residuals)
-->No multicollinearity
-->Residuals are normally distributed
-->Features are independent


Normal Equation vs Gradient Descent 
For small to medium datasets, the normal equation is faster and doesn't require tuning hyperparameters. However, it's computationally expensive for large datasets due to matrix inversion.


(XᵀX) is not invertible?
You’ll get a LinAlgError. This can happen due to multicollinearity or redundant features.

limitations of linear regression
-->Assumes linearity
-->Sensitive to outliers
-->Can’t handle complex relationships
-->Requires normally distributed residuals
